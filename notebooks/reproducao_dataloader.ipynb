{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..') # notebooks folder\n",
    "\n",
    "from data.load_data import LoadData\n",
    "from configs.gate import LoadDataConfig\n",
    "# from configs.baseline import LoadDataConfig\n",
    "from utils import get_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = LoadDataConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = LoadData(**loader_config.__dict__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.get_train_dataloader()\n",
    "val_dl = dataloader.get_val_dataloader()\n",
    "test_dl = dataloader.get_test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293728, 34775, 17276)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset_size, val_dl.dataset_size, test_dl.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_batch in (train_dl):\n",
    "    raw, exam_id, label = train_batch\n",
    "    ecg = get_inputs(raw).to(device)\n",
    "    label = label.to(device).float()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 4096, 12]),\n",
       " tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1662,  0.0991, -1.0671,  ..., -0.6403,  0.2058,  0.8003],\n",
       "          [ 1.1771,  0.1102, -1.0670,  ..., -0.6269,  0.2166,  0.8156],\n",
       "          [ 1.1824,  0.1202, -1.0622,  ..., -0.6216,  0.2292,  0.8360],\n",
       "          ...,\n",
       "          [ 0.6533, -0.3997, -1.0531,  ..., -0.9878, -0.1735,  0.5164],\n",
       "          [ 0.6560, -0.3909, -1.0469,  ..., -0.9722, -0.1617,  0.5186],\n",
       "          [ 0.6530, -0.3886, -1.0416,  ..., -0.9659, -0.1593,  0.5162]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape, raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 12, 2560]),\n",
       " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9702e-01,\n",
       "           -1.9544e-01, -2.1698e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.5979e-01,\n",
       "           -1.9544e-01, -2.0546e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.7229e-02,\n",
       "            2.8250e-19,  1.1518e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.5427e-02,\n",
       "           -6.8403e-02, -6.9504e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.8855e-01,\n",
       "           -1.9544e-01, -1.9638e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.2524e-01,\n",
       "           -1.3681e-01, -1.3644e-01]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -9.5852e-02,\n",
       "           -9.7718e-02, -1.0607e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.4687e-02,\n",
       "           -8.7947e-02, -9.6648e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1165e-02,\n",
       "            9.7718e-03,  9.4180e-03],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.5410e-01,\n",
       "           -2.5407e-01, -2.5551e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9441e-01,\n",
       "           -1.8566e-01, -1.8318e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.6352e-01,\n",
       "           -1.6612e-01, -1.7430e-01]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9995e-01,\n",
       "           -1.4658e-01, -9.2235e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.2991e-01,\n",
       "           -7.8175e-02, -2.7109e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.0042e-02,\n",
       "            6.8403e-02,  6.5126e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.4396e-01,\n",
       "           -1.3681e-01, -1.2292e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9021e-01,\n",
       "           -1.6612e-01, -1.5083e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3550e-01,\n",
       "           -1.2703e-01, -1.1314e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 8.8264e-01,  8.8416e-01,  8.9048e-01,  ...,  6.9361e-01,\n",
       "            6.9299e-01,  6.9058e-01],\n",
       "          [-2.3462e-02, -2.2866e-02, -1.6255e-02,  ..., -3.5061e-01,\n",
       "           -3.5004e-01, -3.5282e-01],\n",
       "          [-9.0610e-01, -9.0702e-01, -9.0673e-01,  ..., -1.0442e+00,\n",
       "           -1.0430e+00, -1.0434e+00],\n",
       "          ...,\n",
       "          [-3.7887e-01, -3.8110e-01, -3.8817e-01,  ..., -9.8324e-01,\n",
       "           -9.7504e-01, -9.7482e-01],\n",
       "          [ 1.9994e-01,  1.9817e-01,  1.9069e-01,  ..., -1.9055e-01,\n",
       "           -1.9123e-01, -1.8941e-01],\n",
       "          [ 5.4824e-01,  5.4879e-01,  5.5308e-01,  ...,  1.8293e-01,\n",
       "            1.7607e-01,  1.7540e-01]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.2237e-02,\n",
       "           -3.9087e-02, -2.5647e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.7080e-02,\n",
       "           -3.9087e-02, -3.9152e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.4844e-02,\n",
       "           -1.5947e-18, -1.3505e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.5343e-02,\n",
       "           -2.9316e-02, -3.7272e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.8484e-02,\n",
       "           -4.8859e-02, -4.8813e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.6832e-02,\n",
       "           -3.9087e-02, -6.1111e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.8807e-01,\n",
       "            1.2703e-01,  8.3372e-02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.8573e-01,\n",
       "           -4.9836e-01, -4.9455e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -6.7380e-01,\n",
       "           -6.2540e-01, -5.7792e-01],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.5473e-01,\n",
       "           -1.9544e-01, -2.2827e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.0290e-01,\n",
       "           -8.0129e-01, -8.6086e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -6.5135e-01,\n",
       "           -7.8175e-01, -8.4099e-01]]], device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg.shape, ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128,),\n",
       " array([3172506,  824319,  652737, 3199595,   18148, 1463563, 1175532,\n",
       "        2654895,   79264,  801107, 3211241, 1285238, 2743211, 1630791,\n",
       "        1499926, 1463771, 1481569, 3169198,  989421,  467853,   86393,\n",
       "        1539302,  122023,  140925,  532209,  617443,  898489,  197210,\n",
       "        2825990,  432213, 2668984, 1370693,   66958,  686823, 1577156,\n",
       "         728647,  216801,   89693,   45289, 3618947,  659567,  594210,\n",
       "         141054, 1577303, 3186816,  476817,  810932,  252111,  989631,\n",
       "         837762,  622994,  411018,  696855, 1178174, 1016170,  622876,\n",
       "        1658897, 3167924, 2658317, 1630955, 1339754,   90606, 1446726,\n",
       "         903665, 1140243,  446125, 4270982, 3204706,  188635,  383852,\n",
       "        1504657, 1155899,  480556,  440161,  292542,  367715, 2516781,\n",
       "        4203670,  785939,  652654,  165093,  964656, 1272654, 1668236,\n",
       "        1266379,  956795, 1293393, 2888861,   15571, 2726021,  586972,\n",
       "        2681431, 1426188, 1520863, 2754004, 3140535,  922947,  826570,\n",
       "        1639360,  833146,   95064, 1157777,  947866, 1269031,    1516,\n",
       "         268826, 1058365, 1455823,  917407,  843246, 3399734, 1519642,\n",
       "         704724, 1172505, 1250899, 2839170, 1721006, 1703909, 1690333,\n",
       "        1753287, 1773277, 1741998, 1742073, 1818528, 1787823, 2024838,\n",
       "        1838279, 2104528], dtype=int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_id.shape, exam_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3]),\n",
       " tensor([[0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.]], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
