{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..') # notebooks folder\n",
    "\n",
    "from data.load_data import LoadData\n",
    "from configs.gate import LoadDataConfig\n",
    "# from configs.baseline import LoadDataConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = LoadDataConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = LoadData(**loader_config.__dict__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "signal_crop_len = 2560\n",
    "signal_non_zero_start = 571"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(batch, apply = \"non_zero\", device = \"cuda\"):\n",
    "        # (B, C, L)\n",
    "        if batch.shape[1] > batch.shape[2]:\n",
    "            batch = batch.permute(0, 2, 1)\n",
    "\n",
    "        B, n_leads, signal_len = batch.shape\n",
    "\n",
    "        if apply == \"non_zero\":\n",
    "            transformed_data = torch.zeros(B, n_leads, signal_crop_len)\n",
    "            for b in range(B):\n",
    "                start = signal_non_zero_start\n",
    "                diff = signal_len - start\n",
    "                if start > diff:\n",
    "                    correction = start - diff\n",
    "                    start -= correction\n",
    "                end = start + signal_crop_len\n",
    "                for l in range(n_leads):\n",
    "                    transformed_data[b, l, :] = batch[b, l, start:end]\n",
    "\n",
    "        else:\n",
    "            transformed_data = batch\n",
    "\n",
    "        return transformed_data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.get_train_dataloader()\n",
    "val_dl = dataloader.get_val_dataloader()\n",
    "test_dl = dataloader.get_test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293728, 34775, 17276)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset_size, val_dl.dataset_size, test_dl.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_batch in (train_dl):\n",
    "    raw, exam_id, label = train_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 4096, 12]),\n",
       " tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1662,  0.0991, -1.0671,  ..., -0.6403,  0.2058,  0.8003],\n",
       "          [ 1.1771,  0.1102, -1.0670,  ..., -0.6269,  0.2166,  0.8156],\n",
       "          [ 1.1824,  0.1202, -1.0622,  ..., -0.6216,  0.2292,  0.8360],\n",
       "          ...,\n",
       "          [ 0.6533, -0.3997, -1.0531,  ..., -0.9878, -0.1735,  0.5164],\n",
       "          [ 0.6560, -0.3909, -1.0469,  ..., -0.9722, -0.1617,  0.5186],\n",
       "          [ 0.6530, -0.3886, -1.0416,  ..., -0.9659, -0.1593,  0.5162]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape, raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128,),\n",
       " array([3172506,  824319,  652737, 3199595,   18148, 1463563, 1175532,\n",
       "        2654895,   79264,  801107, 3211241, 1285238, 2743211, 1630791,\n",
       "        1499926, 1463771, 1481569, 3169198,  989421,  467853,   86393,\n",
       "        1539302,  122023,  140925,  532209,  617443,  898489,  197210,\n",
       "        2825990,  432213, 2668984, 1370693,   66958,  686823, 1577156,\n",
       "         728647,  216801,   89693,   45289, 3618947,  659567,  594210,\n",
       "         141054, 1577303, 3186816,  476817,  810932,  252111,  989631,\n",
       "         837762,  622994,  411018,  696855, 1178174, 1016170,  622876,\n",
       "        1658897, 3167924, 2658317, 1630955, 1339754,   90606, 1446726,\n",
       "         903665, 1140243,  446125, 4270982, 3204706,  188635,  383852,\n",
       "        1504657, 1155899,  480556,  440161,  292542,  367715, 2516781,\n",
       "        4203670,  785939,  652654,  165093,  964656, 1272654, 1668236,\n",
       "        1266379,  956795, 1293393, 2888861,   15571, 2726021,  586972,\n",
       "        2681431, 1426188, 1520863, 2754004, 3140535,  922947,  826570,\n",
       "        1639360,  833146,   95064, 1157777,  947866, 1269031,    1516,\n",
       "         268826, 1058365, 1455823,  917407,  843246, 3399734, 1519642,\n",
       "         704724, 1172505, 1250899, 2839170, 1721006, 1703909, 1690333,\n",
       "        1753287, 1773277, 1741998, 1742073, 1818528, 1787823, 2024838,\n",
       "        1838279, 2104528], dtype=int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_id.shape, exam_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3]),\n",
       " tensor([[0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
