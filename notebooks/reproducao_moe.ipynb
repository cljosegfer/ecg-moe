{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# from configs.baseline import LoadDataConfig, Downstream_cnn_args\n",
    "from configs.fake import LoadDataConfig, Downstream_cnn_args\n",
    "from data.load_data import LoadData\n",
    "from models.baseline import ResnetBaseline\n",
    "from utils import get_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'moe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = LoadDataConfig()\n",
    "resnet_config = Downstream_cnn_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> WARNING: USING RANDOM FAKE DATA!!\n"
     ]
    }
   ],
   "source": [
    "dataloader = LoadData(**loader_config.__dict__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_path = 'output/{}.pt'.format('gate')\n",
    "n_experts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = torch.load(gate_path)\n",
    "experts = [ResnetBaseline(**resnet_config.__dict__) for _ in range(n_experts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = resnet_config.__dict__['n_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dl):\n",
    "        raw, exam_id, label = batch\n",
    "        ecg = get_inputs(raw).to(device)\n",
    "        label = label.to(device).float()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gate.forward(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " tensor([[-0.7242, -0.2769,  0.3864],\n",
       "         [-0.7259, -0.1610,  0.1848]], device='cuda:0', grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = [expert.to(device).forward(ecg) for expert in experts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " [tensor([[ 0.4104, -0.3844, -0.1688,  0.2827,  0.5176,  0.3112],\n",
       "          [ 0.3104, -0.1623,  0.4761,  0.5980, -0.0701,  0.2303]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>),\n",
       "  tensor([[ 0.2689,  0.5607,  0.3637, -0.4390,  0.4115,  0.2966],\n",
       "          [ 0.6865,  0.1736,  0.7279, -0.1427, -0.0597, -0.5079]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>),\n",
       "  tensor([[ 0.0603,  0.0088, -0.6210, -0.0704,  0.0960,  0.7776],\n",
       "          [ 0.2196,  0.9104, -0.3917,  1.0485, -0.0217,  0.3171]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0].shape, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = g.cpu().detach().numpy()\n",
    "# logits = [logit.cpu().detach().numpy() for logit in logits]\n",
    "g = g.cpu().detach()\n",
    "logits = [logit.cpu().detach() for logit in logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3]),\n",
       " tensor([[[-0.7242, -0.2769,  0.3864]],\n",
       " \n",
       "         [[-0.7259, -0.1610,  0.1848]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_expanded = np.expand_dims(g, axis=1)\n",
    "g_expanded = g.unsqueeze(1)\n",
    "g_expanded.shape, g_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 3]),\n",
       " tensor([[[-0.7242, -0.2769,  0.3864],\n",
       "          [-0.7242, -0.2769,  0.3864],\n",
       "          [-0.7242, -0.2769,  0.3864],\n",
       "          [-0.7242, -0.2769,  0.3864],\n",
       "          [-0.7242, -0.2769,  0.3864],\n",
       "          [-0.7242, -0.2769,  0.3864]],\n",
       " \n",
       "         [[-0.7259, -0.1610,  0.1848],\n",
       "          [-0.7259, -0.1610,  0.1848],\n",
       "          [-0.7259, -0.1610,  0.1848],\n",
       "          [-0.7259, -0.1610,  0.1848],\n",
       "          [-0.7259, -0.1610,  0.1848],\n",
       "          [-0.7259, -0.1610,  0.1848]]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_tiled = np.tile(g_expanded, (1, num_classes, 1))\n",
    "g_tiled = g_expanded.expand(-1, num_classes, -1)\n",
    "g_tiled.shape, g_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 3]),\n",
       " tensor([[[ 0.4104,  0.2689,  0.0603],\n",
       "          [-0.3844,  0.5607,  0.0088],\n",
       "          [-0.1688,  0.3637, -0.6210],\n",
       "          [ 0.2827, -0.4390, -0.0704],\n",
       "          [ 0.5176,  0.4115,  0.0960],\n",
       "          [ 0.3112,  0.2966,  0.7776]],\n",
       " \n",
       "         [[ 0.3104,  0.6865,  0.2196],\n",
       "          [-0.1623,  0.1736,  0.9104],\n",
       "          [ 0.4761,  0.7279, -0.3917],\n",
       "          [ 0.5980, -0.1427,  1.0485],\n",
       "          [-0.0701, -0.0597, -0.0217],\n",
       "          [ 0.2303, -0.5079,  0.3171]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits_transposed = np.transpose(logits, axes = (1, 2, 0))\n",
    "logits_transposed = torch.stack(logits, dim = 2)\n",
    "logits_transposed.shape, logits_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " tensor([[-0.3484,  0.1266, -0.2184, -0.1104, -0.4517, -0.0070],\n",
       "         [-0.2952,  0.2581, -0.5352, -0.2173,  0.0565, -0.0267]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yhat = np.sum(g_tiled * logits_transposed, axis = 2)\n",
    "yhat = torch.sum(g_tiled * logits_transposed, dim = 2)\n",
    "yhat.shape, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6),\n",
       " array([[-0.34836203,  0.12657817, -0.21842196, -0.11037884, -0.45170977,\n",
       "         -0.00698128],\n",
       "        [-0.29522881,  0.25810405, -0.53520443, -0.21725466,  0.05647964,\n",
       "         -0.02674845]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.numpy()\n",
    "logits = [logit.numpy() for logit in logits]\n",
    "\n",
    "yhat_for = np.zeros(shape = logits[0].shape)\n",
    "for i in range(loader_config.__dict__['batch_size']):\n",
    "    for j in range(n_experts):\n",
    "        yhat_for[i, :] += g[i, j] * logits[j][i, :]\n",
    "yhat_for.shape, yhat_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(yhat, yhat_for).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetMoE(nn.Module):\n",
    "    def __init__(self, gate_path, resnet_config, n_experts):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gate = torch.load(gate_path)\n",
    "        self.experts = nn.ModuleList()\n",
    "        for _ in range(n_experts):\n",
    "            self.experts.append(ResnetBaseline(**resnet_config.__dict__))\n",
    "        self.num_classes = resnet_config.__dict__['n_classes']\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = self.gate.forward(x)\n",
    "        logits = [expert.forward(x) for expert in self.experts]\n",
    "\n",
    "        g = g.unsqueeze(1)\n",
    "        g = g.expand(-1, self.num_classes, -1)\n",
    "        logits = torch.stack(logits, dim = 2)\n",
    "        logits = torch.sum(g * logits, dim = 2)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetMoE(gate_path, resnet_config, n_experts)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda, next(model.gate.parameters()).is_cuda, next(model.experts[0].parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model.forward(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0043,  0.0012,  0.0036, -0.0449, -0.0240, -0.0502],\n",
       "        [ 0.0017,  0.0003, -0.0101, -0.0131,  0.0006, -0.0136]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model.gate.forward(ecg)\n",
    "logits = [expert.forward(ecg) for expert in model.experts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6),\n",
       " array([[-0.00433787,  0.0012323 ,  0.00359915, -0.04489214, -0.02397117,\n",
       "         -0.05022467],\n",
       "        [ 0.00168308,  0.000309  , -0.01007694, -0.01313952,  0.00055843,\n",
       "         -0.01358158]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.cpu().detach().numpy()\n",
    "logits = [logit.cpu().detach().numpy() for logit in logits]\n",
    "\n",
    "yhat_for = np.zeros(shape = logits[0].shape)\n",
    "for i in range(loader_config.__dict__['batch_size']):\n",
    "    for j in range(n_experts):\n",
    "        yhat_for[i, :] += g[i, j] * logits[j][i, :]\n",
    "yhat_for.shape, yhat_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(yhat.cpu(), yhat_for).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
