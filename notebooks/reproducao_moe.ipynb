{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "# from configs.baseline import LoadDataConfig, Downstream_cnn_args\n",
    "from configs.fake import LoadDataConfig, Downstream_cnn_args\n",
    "from data.load_data import LoadData\n",
    "from models.baseline import ResnetBaseline\n",
    "from utils import get_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'moe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = LoadDataConfig()\n",
    "resnet_config = Downstream_cnn_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> WARNING: USING RANDOM FAKE DATA!!\n"
     ]
    }
   ],
   "source": [
    "dataloader = LoadData(**loader_config.__dict__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_path = 'output/{}.pt'.format('gate')\n",
    "n_experts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = torch.load(gate_path)\n",
    "experts = [ResnetBaseline(**resnet_config.__dict__) for _ in range(n_experts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = resnet_config.__dict__['n_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dl):\n",
    "        raw, exam_id, label = batch\n",
    "        ecg = get_inputs(raw).to(device)\n",
    "        label = label.to(device).float()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gate.forward(ecg)\n",
    "g = torch.sigmoid(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " tensor([[1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "         [1.8848e-03, 3.6716e-01, 6.2015e-01]], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = [expert.to(device).forward(ecg) for expert in experts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " [tensor([[ 0.4856,  0.8151,  0.9983,  0.4227, -0.6620, -0.6500],\n",
       "          [ 0.1341,  0.3821,  0.3847,  1.0778, -1.5524, -0.0611]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>),\n",
       "  tensor([[-0.5103,  0.3201,  1.0194,  0.5512,  0.0159,  0.2435],\n",
       "          [-0.2882,  0.4040, -0.0243, -0.0891,  0.4693, -0.3349]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>),\n",
       "  tensor([[ 0.5113,  0.2070, -0.6829, -0.3501,  0.1526, -0.6137],\n",
       "          [ 0.2547, -0.5813, -0.4381, -0.2162,  0.7637, -0.2244]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward>)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0].shape, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = g.cpu().detach().numpy()\n",
    "# logits = [logit.cpu().detach().numpy() for logit in logits]\n",
    "g = g.cpu().detach()\n",
    "logits = [logit.cpu().detach() for logit in logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3]),\n",
       " tensor([[[1.7541e-04, 5.5993e-05, 9.9973e-01]],\n",
       " \n",
       "         [[1.8848e-03, 3.6716e-01, 6.2015e-01]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_expanded = np.expand_dims(g, axis=1)\n",
    "g_expanded = g.unsqueeze(1)\n",
    "g_expanded.shape, g_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 3]),\n",
       " tensor([[[1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "          [1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "          [1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "          [1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "          [1.7541e-04, 5.5993e-05, 9.9973e-01],\n",
       "          [1.7541e-04, 5.5993e-05, 9.9973e-01]],\n",
       " \n",
       "         [[1.8848e-03, 3.6716e-01, 6.2015e-01],\n",
       "          [1.8848e-03, 3.6716e-01, 6.2015e-01],\n",
       "          [1.8848e-03, 3.6716e-01, 6.2015e-01],\n",
       "          [1.8848e-03, 3.6716e-01, 6.2015e-01],\n",
       "          [1.8848e-03, 3.6716e-01, 6.2015e-01],\n",
       "          [1.8848e-03, 3.6716e-01, 6.2015e-01]]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_tiled = np.tile(g_expanded, (1, num_classes, 1))\n",
    "g_tiled = g_expanded.expand(-1, num_classes, -1)\n",
    "g_tiled.shape, g_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 3]),\n",
       " tensor([[[ 0.4856, -0.5103,  0.5113],\n",
       "          [ 0.8151,  0.3201,  0.2070],\n",
       "          [ 0.9983,  1.0194, -0.6829],\n",
       "          [ 0.4227,  0.5512, -0.3501],\n",
       "          [-0.6620,  0.0159,  0.1526],\n",
       "          [-0.6500,  0.2435, -0.6137]],\n",
       " \n",
       "         [[ 0.1341, -0.2882,  0.2547],\n",
       "          [ 0.3821,  0.4040, -0.5813],\n",
       "          [ 0.3847, -0.0243, -0.4381],\n",
       "          [ 1.0778, -0.0891, -0.2162],\n",
       "          [-1.5524,  0.4693,  0.7637],\n",
       "          [-0.0611, -0.3349, -0.2244]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits_transposed = np.transpose(logits, axes = (1, 2, 0))\n",
    "logits_transposed = torch.stack(logits, dim = 2)\n",
    "logits_transposed.shape, logits_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " tensor([[ 0.5112,  0.2071, -0.6824, -0.3499,  0.1524, -0.6136],\n",
       "         [ 0.0524, -0.2114, -0.2799, -0.1647,  0.6430, -0.2623]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yhat = np.sum(g_tiled * logits_transposed, axis = 2)\n",
    "yhat = torch.sum(g_tiled * logits_transposed, dim = 2)\n",
    "yhat.shape, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6),\n",
       " array([[ 0.51124154,  0.2070664 , -0.68243882, -0.34988201,  0.15244258,\n",
       "         -0.61364974],\n",
       "        [ 0.05243565, -0.21141804, -0.27988988, -0.16473723,  0.64298703,\n",
       "         -0.26226373]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.numpy()\n",
    "logits = [logit.numpy() for logit in logits]\n",
    "\n",
    "yhat_for = np.zeros(shape = logits[0].shape)\n",
    "for i in range(loader_config.__dict__['batch_size']):\n",
    "    for j in range(n_experts):\n",
    "        yhat_for[i, :] += g[i, j] * logits[j][i, :]\n",
    "yhat_for.shape, yhat_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(yhat, yhat_for).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResnetMoE(nn.Module):\n",
    "#     def __init__(self, gate_path, resnet_config, n_experts):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.gate = torch.load(gate_path)\n",
    "#         self.experts = nn.ModuleList()\n",
    "#         for _ in range(n_experts):\n",
    "#             self.experts.append(ResnetBaseline(**resnet_config.__dict__))\n",
    "#         self.num_classes = resnet_config.__dict__['n_classes']\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         g = self.gate.forward(x)\n",
    "#         logits = [expert.forward(x) for expert in self.experts]\n",
    "\n",
    "#         g = g.unsqueeze(1)\n",
    "#         g = g.expand(-1, self.num_classes, -1)\n",
    "#         logits = torch.stack(logits, dim = 2)\n",
    "#         logits = torch.sum(g * logits, dim = 2)\n",
    "\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.moe import MoE_cnn_args\n",
    "from models.moe import ResnetMoE\n",
    "\n",
    "moe_config = MoE_cnn_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetMoE(**moe_config.__dict__)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda, next(model.gate.parameters()).is_cuda, next(model.experts[0].parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model.forward(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0447, -0.0198,  0.0166,  0.0671, -0.0603,  0.0254],\n",
       "        [ 0.0086, -0.0147,  0.0017,  0.0396, -0.0532,  0.0260]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model.gate.forward(ecg)\n",
    "g = torch.sigmoid(g)\n",
    "logits = [expert.forward(ecg) for expert in model.experts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6),\n",
       " array([[ 0.0447257 , -0.01983287,  0.01664077,  0.06708844, -0.06032221,\n",
       "          0.02544975],\n",
       "        [ 0.00858808, -0.01473155,  0.00167097,  0.03960469, -0.05318132,\n",
       "          0.02595899]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.cpu().detach().numpy()\n",
    "logits = [logit.cpu().detach().numpy() for logit in logits]\n",
    "\n",
    "yhat_for = np.zeros(shape = logits[0].shape)\n",
    "for i in range(loader_config.__dict__['batch_size']):\n",
    "    for j in range(n_experts):\n",
    "        yhat_for[i, :] += g[i, j] * logits[j][i, :]\n",
    "yhat_for.shape, yhat_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(yhat.cpu(), yhat_for).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
